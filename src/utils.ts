import { getCachedLogChannel, getVoiceConnection, getActiveThread, setActiveThread } from "./state";
import { config } from "./config";
import {
  createAudioPlayer,
  createAudioResource,
  AudioPlayerStatus,
  VoiceConnectionStatus,
  entersState,
} from "@discordjs/voice";
import * as path from "path";
import * as fs from "fs";
import { pipeline } from "stream/promises";
import { createWriteStream } from "fs";
import { tmpdir } from "os";

/**
 * OpenAI chat completionäº’æ›APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‹
 */
type ChatCompletionResponse = {
  choices?: Array<{
    message?: {
      content?: string;
    };
  }>;
};

/**
 * æ—¥æœ¬æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
 */
export function getJapaneseTimestamp(): string {
  const now = new Date();
  return now.toLocaleString("ja-JP", {
    timeZone: "Asia/Tokyo",
    year: "numeric",
    month: "2-digit",
    day: "2-digit",
    hour: "2-digit",
    minute: "2-digit",
    second: "2-digit",
  });
}

/**
 * ã‚¹ãƒ¬ãƒƒãƒ‰ã¾ãŸã¯ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
 */
export async function sendToThreadOrChannel(message: string): Promise<void> {
  const cachedLogChannel = getCachedLogChannel();
  if (!cachedLogChannel) {
    console.error("Log channel not available");
    return;
  }

  const activeThread = getActiveThread();
  if (activeThread) {
    try {
      await activeThread.send(message);
    } catch (error) {
      console.error("Failed to send to thread, falling back to channel:", error);
      // ã‚¹ãƒ¬ãƒƒãƒ‰é€ä¿¡å¤±æ•—æ™‚ã¯ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      await cachedLogChannel.send(message);
      // ã‚¹ãƒ¬ãƒƒãƒ‰ãŒç„¡åŠ¹ãªã®ã§ã‚¯ãƒªã‚¢
      setActiveThread(null);
    }
  } else {
    await cachedLogChannel.send(message);
  }
}

/**
 * ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«åŠ¹æœéŸ³ã‚’å†ç”Ÿ
 *
 * æ³¨æ„: ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€å®Ÿè¡Œç’°å¢ƒã«FFmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
 * MP3å½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿã™ã‚‹å ´åˆã€Discord.jsã¯FFmpegã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
 *
 * ã‚‚ã—FFmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªã„ç’°å¢ƒã®å ´åˆã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§Ogg Opuså½¢å¼ã«å¤‰æ›ã§ãã¾ã™ï¼š
 * ```bash
 * ffmpeg -i assets/sounds/pin1.mp3 -c:a libopus -b:a 96k assets/sounds/pin1.ogg
 * ```
 * ãã®å¾Œã€soundFilePathã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚
 */
async function playSoundEffect(soundFilePath: string): Promise<void> {
  const connection = getVoiceConnection();

  // ãƒœã‚¤ã‚¹æ¥ç¶šãŒãªã„ã€ã¾ãŸã¯æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
  if (!connection || connection.state.status !== VoiceConnectionStatus.Ready) {
    if (config.VERBOSE) {
      console.log("[Sound] ãƒœã‚¤ã‚¹æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€åŠ¹æœéŸ³ã®å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™");
    }
    return;
  }

  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
  if (!fs.existsSync(soundFilePath)) {
    console.error(`[Sound] åŠ¹æœéŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ${soundFilePath}`);
    return;
  }

  const audioPlayer = createAudioPlayer();
  const subscription = connection.subscribe(audioPlayer);

  audioPlayer.on("error", (error) => {
    console.error("[Sound] åŠ¹æœéŸ³ã®å†ç”Ÿä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", error);
  });

  try {
    const resource = createAudioResource(soundFilePath);
    audioPlayer.play(resource);

    if (config.VERBOSE) {
      console.log(`[Sound] åŠ¹æœéŸ³ã‚’å†ç”Ÿä¸­: ${soundFilePath}`);
    }

    await entersState(audioPlayer, AudioPlayerStatus.Idle, 5_000);
    if (config.VERBOSE) {
      console.log("[Sound] åŠ¹æœéŸ³ã®å†ç”ŸãŒå®Œäº†ã—ã¾ã—ãŸ");
    }
  } catch (error) {
    if (config.VERBOSE) {
      console.log("[Sound] åŠ¹æœéŸ³ã®å†ç”ŸãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¾ãŸã¯å¤±æ•—ã—ã¾ã—ãŸ");
    }
    console.error("[Sound] åŠ¹æœéŸ³ã®å†ç”Ÿå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼:", error);
  } finally {
    subscription?.unsubscribe();
    audioPlayer.stop();
  }
}

/**
 * OpenAIäº’æ›ã®TTS APIã‚’å‘¼ã³å‡ºã—ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
 *
 * @param text éŸ³å£°åˆæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
 * @returns éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯null
 */
async function callTTSAPI(text: string): Promise<string | null> {
  // TTSè¨­å®šãŒä¸å®Œå…¨ãªå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
  if (!config.TTS_ENDPOINT_URL || !config.TTS_MODEL || !config.TTS_VOICE) {
    if (config.VERBOSE) {
      console.log("[TTS] TTS endpoint, model, or voice not configured, skipping TTS");
    }
    return null;
  }

  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 30000); // 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

  try {
    if (config.VERBOSE) {
      console.log(`[TTS] Calling TTS API with model: ${config.TTS_MODEL}, voice: ${config.TTS_VOICE}, speed: ${config.TTS_SPEED}`);
    }

    const response = await fetch(config.TTS_ENDPOINT_URL, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: config.TTS_MODEL,
        voice: config.TTS_VOICE,
        input: text,
        speed: config.TTS_SPEED,
      }),
      signal: controller.signal,
    });

    if (!response.ok) {
      console.error(`[TTS] TTS API request failed with status ${response.status}`);
      return null;
    }

    // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    const tempFilePath = path.join(tmpdir(), `tts-${Date.now()}.mp3`);
    const fileStream = createWriteStream(tempFilePath);

    if (!response.body) {
      console.error("[TTS] No response body from TTS API");
      return null;
    }

    // Node.js Readable streamã«å¤‰æ›ã—ã¦ä¿å­˜
    await pipeline(response.body, fileStream);

    if (config.VERBOSE) {
      console.log(`[TTS] Audio saved to: ${tempFilePath}`);
    }

    return tempFilePath;
  } catch (error) {
    if (error instanceof Error && error.name === "AbortError") {
      console.error("[TTS] TTS request timed out after 30 seconds");
    } else {
      console.error("[TTS] Error calling TTS API:", error);
    }
    return null;
  } finally {
    clearTimeout(timeoutId);
  }
}

/**
 * TTSéŸ³å£°ã‚’ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã§å†ç”Ÿ
 *
 * @param audioFilePath å†ç”Ÿã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
 */
async function playTTSAudio(audioFilePath: string): Promise<void> {
  const connection = getVoiceConnection();

  if (!connection || connection.state.status !== VoiceConnectionStatus.Ready) {
    if (config.VERBOSE) {
      console.log("[TTS] ãƒœã‚¤ã‚¹æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€TTSéŸ³å£°ã®å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™");
    }
    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    try {
      fs.unlinkSync(audioFilePath);
    } catch (error) {
      console.error("[TTS] Failed to delete temp audio file:", error);
    }
    return;
  }

  const audioPlayer = createAudioPlayer();
  const subscription = connection.subscribe(audioPlayer);

  audioPlayer.on("error", (error) => {
    console.error("[TTS] TTSéŸ³å£°ã®å†ç”Ÿä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", error);
  });

  try {
    const resource = createAudioResource(audioFilePath);
    audioPlayer.play(resource);

    if (config.VERBOSE) {
      console.log(`[TTS] TTSéŸ³å£°ã‚’å†ç”Ÿä¸­: ${audioFilePath}`);
    }

    // å†ç”Ÿå®Œäº†ã‚’å¾…æ©Ÿï¼ˆæœ€å¤§60ç§’ï¼‰
    await entersState(audioPlayer, AudioPlayerStatus.Idle, 60_000);

    if (config.VERBOSE) {
      console.log("[TTS] TTSéŸ³å£°ã®å†ç”ŸãŒå®Œäº†ã—ã¾ã—ãŸ");
    }
  } catch (error) {
    if (config.VERBOSE) {
      console.log("[TTS] TTSéŸ³å£°ã®å†ç”ŸãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¾ãŸã¯å¤±æ•—ã—ã¾ã—ãŸ");
    }
    console.error("[TTS] TTSéŸ³å£°ã®å†ç”Ÿå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼:", error);
  } finally {
    subscription?.unsubscribe();
    audioPlayer.stop();

    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    try {
      fs.unlinkSync(audioFilePath);
      if (config.VERBOSE) {
        console.log(`[TTS] ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: ${audioFilePath}`);
      }
    } catch (error) {
      console.error("[TTS] Failed to delete temp audio file:", error);
    }
  }
}

/**
 * OpenAI chat completionäº’æ›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
 */
async function sendChatCompletionRequest(
  transcript: string
): Promise<string | null> {
  // ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLã¨APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
  if (!config.CHAT_COMPLETION_ENDPOINT_URL || !config.CHAT_COMPLETION_APIKEY) {
    if (config.VERBOSE) {
      console.log(
        "[LLM] Chat completion endpoint or API key not configured, skipping LLM processing"
      );
    }
    return null;
  }

  // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ60ç§’ï¼‰
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 60000);

  try {
    // VERBOSEãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã‚’ãƒ­ã‚°å‡ºåŠ›
    if (config.VERBOSE) {
      console.log(
        `[LLM] Sending request with session key: ${config.CHAT_COMPLETION_SESSION_KEY}`
      );
      console.log(`[LLM] Using model: ${config.CHAT_COMPLETION_MODEL}`);
    }

    const response = await fetch(config.CHAT_COMPLETION_ENDPOINT_URL, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${config.CHAT_COMPLETION_APIKEY}`,
        "x-openclaw-session-key": config.CHAT_COMPLETION_SESSION_KEY,
      },
      body: JSON.stringify({
        model: config.CHAT_COMPLETION_MODEL,
        messages: [
          {
            role: "user",
            content: transcript,
          },
        ],
      }),
      signal: controller.signal,
    });

    if (!response.ok) {
      console.error(
        `[LLM] Chat completion request failed with status ${response.status}`
      );
      return null;
    }

    const data = (await response.json()) as ChatCompletionResponse;
    const llmResponse = data.choices?.[0]?.message?.content;

    if (!llmResponse) {
      console.error("[LLM] No content in chat completion response");
      return null;
    }

    return llmResponse;
  } catch (error) {
    // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã«è¨˜éŒ²
    if (error instanceof Error && error.name === "AbortError") {
      console.error("[LLM] Request timed out after 60 seconds");
      const timestamp = getJapaneseTimestamp();
      const timeoutMessage = `âš ï¸ **LLMã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ** â€” ${timestamp}\nLLMã‹ã‚‰ã®å¿œç­”ãŒ60ç§’ä»¥å†…ã«å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚`;
      sendToThreadOrChannel(timeoutMessage).catch((sendError) =>
        console.error(
          "[LLM] Failed to send timeout message to channel:",
          sendError
        )
      );
    } else {
      console.error("[LLM] Error sending chat completion request:", error);
    }
    return null;
  } finally {
    clearTimeout(timeoutId);
  }
}

/**
 * ãƒœã‚¤ã‚¹ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã«æ–‡å­—èµ·ã“ã—ã‚’æŠ•ç¨¿
 */
export async function sendTranscriptionToChannel(
  username: string,
  transcript: string
) {
  const cachedLogChannel = getCachedLogChannel();
  if (!cachedLogChannel || !transcript.trim()) return;

  try {
    const timestamp = getJapaneseTimestamp();
    const message = `ğŸ’¬ **${username}** â€” ${timestamp}\n${transcript}`;
    await sendToThreadOrChannel(message);
    console.log(`[Transcription] ${username}: ${transcript}`);

    // LLMã«æ–‡å­—èµ·ã“ã—çµæœã‚’é€ä¿¡ã—ã¦å‡¦ç†ï¼ˆéåŒæœŸã§ä¸¦è¡Œå®Ÿè¡Œï¼‰
    (async () => {
      try {
        // LLMã«é€ä¿¡ã™ã‚‹å‰ã«åŠ¹æœéŸ³ã‚’å†ç”Ÿ
        const soundPath = path.isAbsolute(config.SOUND_EFFECT_PATH)
          ? config.SOUND_EFFECT_PATH
          : path.join(__dirname, "..", config.SOUND_EFFECT_PATH);
        await playSoundEffect(soundPath);

        const llmResponse = await sendChatCompletionRequest(transcript);
        if (llmResponse) {
          const llmTimestamp = getJapaneseTimestamp();
          const llmMessage = `ğŸ¤– **LLMå¿œç­”** â€” ${llmTimestamp}\n${llmResponse}`;

          // ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã¾ãŸã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¹ãƒ¬ãƒƒãƒ‰ã«æŠ•ç¨¿ï¼ˆã“ã‚Œã¯å¾…æ©Ÿã™ã‚‹ï¼‰
          await sendToThreadOrChannel(llmMessage);

          // TTSéŸ³å£°å†ç”Ÿã¯éåŒæœŸã§å®Ÿè¡Œï¼ˆå¾…æ©Ÿã—ãªã„ï¼‰
          (async () => {
            const audioFilePath = await callTTSAPI(llmResponse);
            if (audioFilePath) {
              await playTTSAudio(audioFilePath);
            }
          })().catch((error) => {
            console.error("[TTS] Error in TTS playback:", error);
          });

          if (config.VERBOSE) {
            console.log(`[LLM] Response sent to channel for: ${transcript}`);
          }
        }
      } catch (error) {
        console.error("[LLM] Error processing and sending LLM response:", error);
        // ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã«ã‚¨ãƒ©ãƒ¼ã‚’é€šçŸ¥
        try {
          const timestamp = getJapaneseTimestamp();
          const errorMessage = `âŒ **LLMã‚¨ãƒ©ãƒ¼** â€” ${timestamp}\nLLMå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : String(error)}`;
          await sendToThreadOrChannel(errorMessage);
        } catch (sendError) {
          console.error(
            "[LLM] Failed to send error message to channel:",
            sendError
          );
        }
      }
    })();
  } catch (error) {
    console.error("Error sending transcription:", error);
  }
}
