import { getCachedLogChannel, getVoiceConnection } from "./state";
import { config } from "./config";
import {
  createAudioPlayer,
  createAudioResource,
  AudioPlayerStatus,
  VoiceConnectionStatus,
} from "@discordjs/voice";
import * as path from "path";
import * as fs from "fs";

/**
 * OpenAI chat completionäº’æ›APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‹
 */
type ChatCompletionResponse = {
  choices?: Array<{
    message?: {
      content?: string;
    };
  }>;
};

/**
 * æ—¥æœ¬æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
 */
export function getJapaneseTimestamp(): string {
  const now = new Date();
  return now.toLocaleString("ja-JP", {
    timeZone: "Asia/Tokyo",
    year: "numeric",
    month: "2-digit",
    day: "2-digit",
    hour: "2-digit",
    minute: "2-digit",
    second: "2-digit",
  });
}

/**
 * ãƒœã‚¤ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«ã«åŠ¹æœéŸ³ã‚’å†ç”Ÿ
 */
async function playSoundEffect(soundFilePath: string): Promise<void> {
  const connection = getVoiceConnection();

  // ãƒœã‚¤ã‚¹æ¥ç¶šãŒãªã„ã€ã¾ãŸã¯æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
  if (!connection || connection.state.status !== VoiceConnectionStatus.Ready) {
    if (config.VERBOSE) {
      console.log("[Sound] ãƒœã‚¤ã‚¹æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€åŠ¹æœéŸ³ã®å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™");
    }
    return;
  }

  // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
  if (!fs.existsSync(soundFilePath)) {
    console.error(`[Sound] åŠ¹æœéŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ${soundFilePath}`);
    return;
  }

  try {
    const audioPlayer = createAudioPlayer();
    const resource = createAudioResource(soundFilePath);

    audioPlayer.play(resource);
    connection.subscribe(audioPlayer);

    if (config.VERBOSE) {
      console.log(`[Sound] åŠ¹æœéŸ³ã‚’å†ç”Ÿä¸­: ${soundFilePath}`);
    }

    // å†ç”Ÿå®Œäº†ã‚’å¾…æ©Ÿ
    await new Promise<void>((resolve) => {
      audioPlayer.on(AudioPlayerStatus.Idle, () => {
        if (config.VERBOSE) {
          console.log("[Sound] åŠ¹æœéŸ³ã®å†ç”ŸãŒå®Œäº†ã—ã¾ã—ãŸ");
        }
        resolve();
      });

      // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
      audioPlayer.on("error", (error) => {
        console.error("[Sound] åŠ¹æœéŸ³ã®å†ç”Ÿä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", error);
        resolve();
      });

      // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ5ç§’ï¼‰
      setTimeout(() => {
        if (config.VERBOSE) {
          console.log("[Sound] åŠ¹æœéŸ³ã®å†ç”ŸãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ");
        }
        resolve();
      }, 5000);
    });
  } catch (error) {
    console.error("[Sound] åŠ¹æœéŸ³ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸ:", error);
  }
}

/**
 * OpenAI chat completionäº’æ›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
 */
async function sendChatCompletionRequest(
  transcript: string
): Promise<string | null> {
  // ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLã¨APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
  if (!config.CHAT_COMPLETION_ENDPOINT_URL || !config.CHAT_COMPLETION_APIKEY) {
    if (config.VERBOSE) {
      console.log(
        "[LLM] Chat completion endpoint or API key not configured, skipping LLM processing"
      );
    }
    return null;
  }

  // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ60ç§’ï¼‰
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 60000);

  try {
    // VERBOSEãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã‚’ãƒ­ã‚°å‡ºåŠ›
    if (config.VERBOSE) {
      console.log(
        `[LLM] Sending request with session key: ${config.CHAT_COMPLETION_SESSION_KEY}`
      );
      console.log(`[LLM] Using model: ${config.CHAT_COMPLETION_MODEL}`);
    }

    const response = await fetch(config.CHAT_COMPLETION_ENDPOINT_URL, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${config.CHAT_COMPLETION_APIKEY}`,
        "x-openclaw-session-key": config.CHAT_COMPLETION_SESSION_KEY,
      },
      body: JSON.stringify({
        model: config.CHAT_COMPLETION_MODEL,
        messages: [
          {
            role: "user",
            content: transcript,
          },
        ],
      }),
      signal: controller.signal,
    });

    if (!response.ok) {
      console.error(
        `[LLM] Chat completion request failed with status ${response.status}`
      );
      return null;
    }

    const data = (await response.json()) as ChatCompletionResponse;
    const llmResponse = data.choices?.[0]?.message?.content;

    if (!llmResponse) {
      console.error("[LLM] No content in chat completion response");
      return null;
    }

    return llmResponse;
  } catch (error) {
    // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã«è¨˜éŒ²
    if (error instanceof Error && error.name === "AbortError") {
      console.error("[LLM] Request timed out after 60 seconds");
      const cachedLogChannel = getCachedLogChannel();
      if (cachedLogChannel) {
        const timestamp = getJapaneseTimestamp();
        const timeoutMessage = `âš ï¸ **LLMã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ** â€” ${timestamp}\nLLMã‹ã‚‰ã®å¿œç­”ãŒ60ç§’ä»¥å†…ã«å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚`;
        cachedLogChannel
          .send(timeoutMessage)
          .catch((sendError) =>
            console.error(
              "[LLM] Failed to send timeout message to channel:",
              sendError
            )
          );
      }
    } else {
      console.error("[LLM] Error sending chat completion request:", error);
    }
    return null;
  } finally {
    clearTimeout(timeoutId);
  }
}

/**
 * ãƒœã‚¤ã‚¹ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã«æ–‡å­—èµ·ã“ã—ã‚’æŠ•ç¨¿
 */
export async function sendTranscriptionToChannel(
  username: string,
  transcript: string
) {
  const cachedLogChannel = getCachedLogChannel();
  if (!cachedLogChannel || !transcript.trim()) return;

  try {
    const timestamp = getJapaneseTimestamp();
    const message = `ğŸ’¬ **${username}** â€” ${timestamp}\n${transcript}`;
    await cachedLogChannel.send(message);
    console.log(`[Transcription] ${username}: ${transcript}`);

    // LLMã«æ–‡å­—èµ·ã“ã—çµæœã‚’é€ä¿¡ã—ã¦å‡¦ç†ï¼ˆéåŒæœŸã§ä¸¦è¡Œå®Ÿè¡Œï¼‰
    (async () => {
      try {
        // LLMã«é€ä¿¡ã™ã‚‹å‰ã«åŠ¹æœéŸ³ã‚’å†ç”Ÿ
        const soundPath = path.join(__dirname, "..", "assets", "sounds", "pin1.mp3");
        await playSoundEffect(soundPath);

        const llmResponse = await sendChatCompletionRequest(transcript);
        if (llmResponse) {
          const llmTimestamp = getJapaneseTimestamp();
          const llmMessage = `ğŸ¤– **LLMå¿œç­”** â€” ${llmTimestamp}\n${llmResponse}`;
          await cachedLogChannel.send(llmMessage);
          if (config.VERBOSE) {
            console.log(`[LLM] Response sent to channel for: ${transcript}`);
          }
        }
      } catch (error) {
        console.error("[LLM] Error processing and sending LLM response:", error);
        // ãƒ­ã‚°ãƒãƒ£ãƒ³ãƒãƒ«ã«ã‚¨ãƒ©ãƒ¼ã‚’é€šçŸ¥
        try {
          const timestamp = getJapaneseTimestamp();
          const errorMessage = `âŒ **LLMã‚¨ãƒ©ãƒ¼** â€” ${timestamp}\nLLMå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : String(error)}`;
          await cachedLogChannel.send(errorMessage);
        } catch (sendError) {
          console.error(
            "[LLM] Failed to send error message to channel:",
            sendError
          );
        }
      }
    })();
  } catch (error) {
    console.error("Error sending transcription:", error);
  }
}
